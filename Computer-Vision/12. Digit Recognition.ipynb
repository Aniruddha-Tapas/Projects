{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Digit Recognition using OpenCV and Scikit-Learn\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Problem:\n",
    "Digit recognition is the ability of a computer to receive and interpret intelligible handwritten numerical input from sources such as paper documents, images, touch-screens and other devices. In this example, we will see how to build a digit recognizer application that takes the input of an image and recognizes the handwritten digits in that image. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Data Set:\n",
    "The data used for this problem is the classical MNIST (\"Modified National Institute of Standards and Technology\") dataset which is extensively studied in the Machine Learning Community. \n",
    "\n",
    "The MNIST database is a set of 70000 samples of handwritten digits where each sample consists of 28×28 sized grayscale images. We will be using sklearn.datasets package to download the MNIST database. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1. Training the Digit Classifier:\n",
    "Here, we will : –\n",
    "\n",
    "1. Calculate the Histogram of Oriented Gaussians(HOG) features for each sample in the database.\n",
    "2. Train a multi-class linear SVM with the HOG features of each sample along with the corresponding label.\n",
    "3. Save the classifier in a file so that we can use the classifier again without performing training each time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of digits in dataset Counter({1: 7877, 7: 7293, 3: 7141, 2: 6990, 9: 6958, 0: 6903, 6: 6876, 8: 6825, 4: 6824, 5: 6313})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['digits_cls.pkl']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing the modules\n",
    "from sklearn.externals import joblib\n",
    "from sklearn import datasets\n",
    "from skimage.feature import hog\n",
    "from sklearn.svm import LinearSVC\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "# Load the dataset\n",
    "# This might take some time as a process of downloading about 55mb of data would be going on.\n",
    "dataset = datasets.fetch_mldata(\"MNIST Original\")\n",
    "\n",
    "# Once, the dataset is downloaded we will save the images of the digits in a numpy array features and the corresponding labels\n",
    "# i.e. the digit in another numpy array labels\n",
    "# Extract the features and labels\n",
    "features = np.array(dataset.data, 'int16') \n",
    "labels = np.array(dataset.target, 'int')\n",
    "\n",
    "# Calculate the HOG features for each image in the database and save them in another numpy array named hog_feature.\n",
    "list_hog_fd = []\n",
    "for feature in features:\n",
    "    fd = hog(feature.reshape((28, 28)), orientations=9, pixels_per_cell=(14, 14), cells_per_block=(1, 1), visualise=False)\n",
    "    list_hog_fd.append(fd)\n",
    "hog_features = np.array(list_hog_fd, 'float64')\n",
    "\n",
    "print \"Count of digits in dataset\", Counter(labels)\n",
    "\n",
    "# The next step is to create a Linear SVM object. Since there are 10 digits, we need a multi-class classifier. \n",
    "# The Linear SVM that comes with sklearn can perform multi-class classification.\n",
    "clf = LinearSVC()\n",
    "\n",
    "# Perform the training using the fit function of clf\n",
    "clf.fit(hog_features, labels)\n",
    "\n",
    "# Save the classifier\n",
    "joblib.dump(clf, \"digits_cls.pkl\", compress=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The crux of this code to tain our digit classifier after the initial loading of digit dataset and extracting the features and labels, is extracting the HOG features.\n",
    "\n",
    "The arguments passed in the _hog()_ functions are explained below:<br>\n",
    "We set the number of cells in each block equal to one and each individual cell is of size 14×14. Since our image is of size 28×28, we will have four blocks/cells of size 14×14 each. Also, we set the size of orientation vector equal to 9. So our HOG feature vector for each sample will be of size 4×9 = 36. We are not interesting in visualizing the HOG feature image, so we will set the visualise parameter to false. \n",
    "\n",
    "After this step we create the _LinearSVM()_ object to do multi-classification.\n",
    "\n",
    "Then we train our classifier using the fit() function which takes two parameters:\n",
    "1. an array of the HOG features of the handwritten digit earlier calculated \n",
    "2. Corresponding array of labels. \n",
    "Each label value is from the set — [0, 1, 2, 3,…, 8, 9]. \n",
    "\n",
    "When the training finishes, we will save the classifier in a file named digits_cls.pkl using _joblib.dump()_ function which has parameters of:\n",
    "1. The classifier object\n",
    "2. Filename where we want to save the classifier\n",
    "3. The compression degree ranging from 0-9. 0 means no compression whereas higher degree means more compression althoug poor computation time. Results have show compression = 3 proves to be a good trade-off.\n",
    "\n",
    "**Thus we have successfully trained our digits classifier.**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step2.  Recognizing digits using our classifier:\n",
    "Now that our classifeir is ready, we can test it on an input of actual digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "from sklearn.externals import joblib\n",
    "from skimage.feature import hog\n",
    "import numpy as np\n",
    "\n",
    "# Load the classifier\n",
    "clf = joblib.load(\"digits_cls.pkl\")\n",
    "\n",
    "# Read the input image \n",
    "im = cv2.imread(\"images/hdigits.jpg\")\n",
    "\n",
    "# Convert to grayscale and apply Gaussian filtering\n",
    "im_gray = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
    "im_gray = cv2.GaussianBlur(im_gray, (5, 5), 0)\n",
    "\n",
    "# Threshold the image\n",
    "ret, im_th = cv2.threshold(im_gray, 90, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "# Find contours in the image\n",
    "_,ctrs,_ = cv2.findContours(im_th.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Get rectangles contains each contour\n",
    "rects = [cv2.boundingRect(ctr) for ctr in ctrs]\n",
    "\n",
    "# For each rectangular region, calculate HOG features and predict\n",
    "# the digit using Linear SVM.\n",
    "for rect in rects:\n",
    "    # Draw the rectangles\n",
    "    cv2.rectangle(im, (rect[0], rect[1]), (rect[0] + rect[2], rect[1] + rect[3]), (0, 255, 0), 3) \n",
    "    # Make the rectangular region around the digit\n",
    "    leng = int(rect[3] * 1.6)\n",
    "    pt1 = int(rect[1] + rect[3] // 2 - leng // 2)\n",
    "    pt2 = int(rect[0] + rect[2] // 2 - leng // 2)\n",
    "    roi = im_th[pt1:pt1+leng, pt2:pt2+leng]\n",
    "    # Resize the image\n",
    "    roi = cv2.resize(roi, (28, 28), interpolation=cv2.INTER_AREA)\n",
    "    roi = cv2.dilate(roi, (3, 3))\n",
    "    # Calculate the HOG features\n",
    "    roi_hog_fd = hog(roi, orientations=9, pixels_per_cell=(14, 14), cells_per_block=(1, 1), visualise=False)\n",
    "    nbr = clf.predict(np.array([roi_hog_fd], 'float64'))\n",
    "    cv2.putText(im, str(int(nbr[0])), (rect[0], rect[1]),cv2.FONT_HERSHEY_DUPLEX, 2, (0, 255, 255), 3)\n",
    "\n",
    "cv2.imshow(\"Digit Recognizer\", im)\n",
    "cv2.waitKey()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For testing our calssifier on real input, we loaded the classifier from the file digits_cls.pkl which we had saved in the previous script.\n",
    "\n",
    "Then we load the test image, convert it to a grayscale image as we have seen before and then apply a Gaussian filter to it so for smoothing. \n",
    "\n",
    "Next we convert our grayscale image into a binary image using a threshold value of 90. All the pixel locations with grayscale values greater than 90 are set to 0(black)in the binary image and all the pixel locations with grayscale values less than 90 are set to 255(white) in the binary image. \n",
    "\n",
    "We calculate the contours in the image, calculate the bounding box for each contour and then generate a bounding square around each contour for each corresponding bounding box. \n",
    "\n",
    "Next we then resize each bounding square to a size of 28×28 and dilate it.\n",
    "\n",
    "We calculate the HOG features for each bounding square. (The HOG feature vector for each bounding square should be of the same size for which the classifier was trained, else you will get an error). \n",
    "\n",
    "Finally, we predict the digit using our classifier. We also draw the bounding box and the predicted digit on the input image. and then display the image.\n",
    "\n",
    "I tested the classifier on this image - \n",
    "\n",
    "<img src=\"images/hd.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting output with the digits recognized looked like this:\n",
    "\n",
    "<img src=\"captures/digitrecognizer.png\">\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE**: While using your own images for testing:\n",
    "\n",
    "Make sure each is at a sufficient distance from each other. Otherwise if the digits are too close, they will interfere in the square region around each digit. In this case, we will need to create a new square image and then we need to copy the contour in that square image.\n",
    "\n",
    "For the images I used in testing,  fixed thresholding worked pretty well. In most real world images, fixed thresholding does not produce good results. In this case, we need to use adaptive thresholding.\n",
    "\n",
    "In the pre-processing step, we only did Gaussian blurring. In most situations, on the binary image we will need to open and close the image to remove small noise pixels and fill small holes ie perform appropriate Image Denoising and Inpainting.\n",
    "\n",
    "Thus here we discussed how we can recognize handwritten digits using OpenCV and Scikit-Learn. We trained a Linear SVM with the HOG features of each sample and then ultimately tested our code.\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying Clustering to learn features in a Semi-Supervised Learning Model\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Here we will combine clustering with classification in a semi-supervised\n",
    "learning problem. You will learn features by clustering unlabeled data and use the\n",
    "learned features to build a supervised classifier._\n",
    "\n",
    "## The Problem : Clustering to learn features\n",
    "In this example we will build a semi-supervised learning system that can classify\n",
    "images of cats and dogs.\n",
    "We will cluster the descriptors extracted from all of\n",
    "the images to learn features. We will then represent an image with a vector with one\n",
    "element for each cluster. Each element will encode the number of descriptors extracted\n",
    "from the image that were assigned to the cluster. This approach is sometimes called\n",
    "the bag-of-features representation, as the collection of clusters is analogous to the\n",
    "bag-of-words representation's vocabulary.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Data Set\n",
    "We will use 1,000 images of cats and 1,000\n",
    "images of dogs from the training set for Kaggle's Dogs vs. Cats competition. The dataset\n",
    "can be downloaded from https://www.kaggle.com/c/dogs-vs-cats/data. We\n",
    "will label cats as the positive class and dogs as the negative class. Note that the images\n",
    "have different dimensions; since our feature vectors do not represent pixels, we do not\n",
    "need to resize the images to have the same dimensions. We will train using the first 60\n",
    "percent of the images, and test on the remaining 40 percent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import mahotas as mh\n",
    "from mahotas.features import surf\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import *\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A na√Øve approach to classifying images would be to use the intensities, or brightnesses, of all of the pixels as\n",
    "explanatory variables. This approach produces high-dimensional feature , non-sparse vectors for\n",
    "even small images. Furthermore, this approach\n",
    "is sensitive to the image's illumination, scale, and orientation.\n",
    "\n",
    "Speeded-Up Robust Features (SURF) is a method for extracting features from an\n",
    "image that is less sensitive to the scale, rotation, and illumination of the image. SURF is more effective at recognizing features across images that have been transformed in certain ways.\n",
    "\n",
    "## Loading the images, converting into grayscale, and extracting the SURF descriptors. \n",
    "SURF descriptors can be extracted more quickly than many similar\n",
    "features, but extracting descriptors from 2,000 images is still computationally\n",
    "expensive and hence would require several minutes for execution on most computers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Reading image:', 'datasets/train\\\\cat.0.jpg')\n",
      "('Reading image:', 'datasets/train\\\\cat.1.jpg')\n",
      "('Reading image:', 'datasets/train\\\\cat.10.jpg')\n",
      "('Reading image:', 'datasets/train\\\\cat.100.jpg')\n",
      "('Reading image:', 'datasets/train\\\\cat.1000.jpg')\n",
      "('Reading image:', 'datasets/train\\\\cat.10000.jpg')\n",
      "('Reading image:', 'datasets/train\\\\cat.10001.jpg')\n",
      "('Reading image:', 'datasets/train\\\\cat.10002.jpg')\n",
      "('Reading image:', 'datasets/train\\\\cat.10003.jpg')\n",
      "('Reading image:', 'datasets/train\\\\cat.10004.jpg')\n",
      "('Reading image:', 'datasets/train\\\\cat.10005.jpg')\n",
      "('Reading image:', 'datasets/train\\\\cat.10006.jpg')\n",
      "('Reading image:', 'datasets/train\\\\cat.10007.jpg')\n",
      "('Reading image:', 'datasets/train\\\\cat.10008.jpg')\n",
      "('Reading image:', 'datasets/train\\\\cat.10009.jpg')\n",
      "('Reading image:', 'datasets/train\\\\cat.1001.jpg')\n",
      "('Reading image:', 'datasets/train\\\\cat.10010.jpg')\n",
      "('Reading image:', 'datasets/train\\\\cat.10011.jpg')\n",
      "('Reading image:', 'datasets/train\\\\cat.10012.jpg')\n",
      "('Reading image:', 'datasets/train\\\\cat.10013.jpg')\n",
      "('Reading image:', 'datasets/train\\\\cat.10014.jpg')\n",
      "('Reading image:', 'datasets/train\\\\cat.10015.jpg')\n",
      "('Reading image:', 'datasets/train\\\\cat.10016.jpg')\n",
      "('Reading image:', 'datasets/train\\\\cat.10017.jpg')\n",
      "('Reading image:', 'datasets/train\\\\cat.10018.jpg')\n",
      "('Reading image:', 'datasets/train\\\\cat.10019.jpg')\n",
      "('Reading image:', 'datasets/train\\\\cat.1002.jpg')\n",
      "('Reading image:', 'datasets/train\\\\cat.10020.jpg')\n",
      "('Reading image:', 'datasets/train\\\\cat.10021.jpg')\n",
      "('Reading image:', 'datasets/train\\\\cat.10022.jpg')\n",
      "('Reading image:', 'datasets/train\\\\cat.10023.jpg')\n",
      "('Reading image:', 'datasets/train\\\\cat.10024.jpg')\n",
      "('Reading image:', 'datasets/train\\\\cat.10025.jpg')\n",
      "('Reading image:', 'datasets/train\\\\cat.10026.jpg')\n",
      "('Reading image:', 'datasets/train\\\\cat.10027.jpg')\n",
      "('Reading image:', 'datasets/train\\\\cat.10028.jpg')\n",
      "('Reading image:', 'datasets/train\\\\cat.10029.jpg')\n",
      "('Reading image:', 'datasets/train\\\\cat.1003.jpg')\n",
      "('Reading image:', 'datasets/train\\\\cat.10030.jpg')\n",
      "('Reading image:', 'datasets/train\\\\cat.10031.jpg')\n",
      "('Reading image:', 'datasets/train\\\\cat.10032.jpg')\n",
      "('Reading image:', 'datasets/train\\\\cat.10033.jpg')\n",
      "('Reading image:', 'datasets/train\\\\cat.10034.jpg')\n",
      "('Reading image:', 'datasets/train\\\\cat.10035.jpg')\n",
      "('Reading image:', 'datasets/train\\\\cat.10036.jpg')\n",
      "('Reading image:', 'datasets/train\\\\cat.10037.jpg')\n",
      "('Reading image:', 'datasets/train\\\\cat.10038.jpg')\n",
      "('Reading image:', 'datasets/train\\\\cat.10039.jpg')\n",
      "('Reading image:', 'datasets/train\\\\cat.1004.jpg')\n",
      "('Reading image:', 'datasets/train\\\\cat.10040.jpg')\n",
      "('Reading image:', 'datasets/train\\\\cat.10041.jpg')\n",
      "('Reading image:', 'datasets/train\\\\cat.10042.jpg')\n",
      "('Reading image:', 'datasets/train\\\\cat.10043.jpg')\n",
      "('Reading image:', 'datasets/train\\\\cat.10044.jpg')\n",
      "('Reading image:', 'datasets/train\\\\cat.10045.jpg')\n",
      "('Reading image:', 'datasets/train\\\\cat.10046.jpg')\n",
      "('Reading image:', 'datasets/train\\\\cat.10047.jpg')\n",
      "('Reading image:', 'datasets/train\\\\cat.10048.jpg')\n",
      "('Reading image:', 'datasets/train\\\\cat.10049.jpg')\n",
      "('Reading image:', 'datasets/train\\\\cat.1005.jpg')\n",
      "('Reading image:', 'datasets/train\\\\cat.10050.jpg')\n",
      "('Reading image:', 'datasets/train\\\\cat.10051.jpg')\n",
      "('Reading image:', 'datasets/train\\\\cat.10052.jpg')\n",
      "('Reading image:', 'datasets/train\\\\cat.10053.jpg')\n",
      "('Reading image:', 'datasets/train\\\\cat.10054.jpg')\n",
      "('Reading image:', 'datasets/train\\\\cat.10055.jpg')\n",
      "('Reading image:', 'datasets/train\\\\cat.10056.jpg')\n",
      "('Reading image:', 'datasets/train\\\\cat.10057.jpg')\n",
      "('Reading image:', 'datasets/train\\\\cat.10058.jpg')\n",
      "('Reading image:', 'datasets/train\\\\cat.10059.jpg')\n",
      "('Reading image:', 'datasets/train\\\\cat.1006.jpg')\n",
      "('Reading image:', 'datasets/train\\\\cat.10060.jpg')\n",
      "('Reading image:', 'datasets/train\\\\cat.10061.jpg')\n",
      "('Reading image:', 'datasets/train\\\\cat.10062.jpg')\n",
      "('Reading image:', 'datasets/train\\\\cat.10063.jpg')\n",
      "('Reading image:', 'datasets/train\\\\cat.10064.jpg')\n",
      "('Reading image:', 'datasets/train\\\\cat.10065.jpg')\n",
      "('Reading image:', 'datasets/train\\\\cat.10066.jpg')\n",
      "('Reading image:', 'datasets/train\\\\cat.10067.jpg')\n",
      "('Reading image:', 'datasets/train\\\\cat.10068.jpg')\n",
      "('Reading image:', 'datasets/train\\\\cat.10069.jpg')\n",
      "('Reading image:', 'datasets/train\\\\cat.1007.jpg')\n",
      "('Reading image:', 'datasets/train\\\\cat.10070.jpg')\n",
      "('Reading image:', 'datasets/train\\\\cat.10071.jpg')\n",
      "('Reading image:', 'datasets/train\\\\cat.10072.jpg')\n",
      "('Reading image:', 'datasets/train\\\\cat.10073.jpg')\n",
      "('Reading image:', 'datasets/train\\\\cat.10074.jpg')\n",
      "('Reading image:', 'datasets/train\\\\cat.10075.jpg')\n",
      "('Reading image:', 'datasets/train\\\\cat.10076.jpg')\n",
      "('Reading image:', 'datasets/train\\\\cat.10077.jpg')\n",
      "('Reading image:', 'datasets/train\\\\cat.10078.jpg')\n",
      "('Reading image:', 'datasets/train\\\\cat.10079.jpg')\n",
      "('Reading image:', 'datasets/train\\\\cat.1008.jpg')\n",
      "('Reading image:', 'datasets/train\\\\cat.10080.jpg')\n",
      "('Reading image:', 'datasets/train\\\\cat.10081.jpg')\n",
      "('Reading image:', 'datasets/train\\\\cat.10082.jpg')\n",
      "('Reading image:', 'datasets/train\\\\cat.10083.jpg')\n",
      "('Reading image:', 'datasets/train\\\\cat.10084.jpg')\n",
      "('Reading image:', 'datasets/train\\\\cat.10085.jpg')\n",
      "('Reading image:', 'datasets/train\\\\cat.10086.jpg')\n",
      "('Reading image:', 'datasets/train\\\\cat.10087.jpg')\n",
      "('Reading image:', 'datasets/train\\\\cat.10088.jpg')\n",
      "('Reading image:', 'datasets/train\\\\cat.10089.jpg')\n",
      "('Reading image:', 'datasets/train\\\\cat.1009.jpg')\n",
      "('Reading image:', 'datasets/train\\\\cat.10090.jpg')\n",
      "('Reading image:', 'datasets/train\\\\cat.10091.jpg')\n",
      "('Reading image:', 'datasets/train\\\\cat.10092.jpg')\n",
      "('Reading image:', 'datasets/train\\\\cat.10093.jpg')\n",
      "('Reading image:', 'datasets/train\\\\cat.10094.jpg')\n",
      "('Reading image:', 'datasets/train\\\\cat.10095.jpg')\n",
      "('Reading image:', 'datasets/train\\\\cat.10096.jpg')\n",
      "('Reading image:', 'datasets/train\\\\cat.10097.jpg')\n",
      "('Reading image:', 'datasets/train\\\\cat.10098.jpg')\n",
      "('Reading image:', 'datasets/train\\\\cat.10099.jpg')\n",
      "('Reading image:', 'datasets/train\\\\cat.101.jpg')\n",
      "('Reading image:', 'datasets/train\\\\cat.1010.jpg')\n",
      "('Reading image:', 'datasets/train\\\\cat.10100.jpg')\n",
      "('Reading image:', 'datasets/train\\\\cat.10101.jpg')\n",
      "('Reading image:', 'datasets/train\\\\cat.10102.jpg')\n",
      "('Reading image:', 'datasets/train\\\\cat.10103.jpg')\n",
      "('Reading image:', 'datasets/train\\\\cat.10104.jpg')\n",
      "('Reading image:', 'datasets/train\\\\cat.10105.jpg')\n",
      "('Reading image:', 'datasets/train\\\\cat.10106.jpg')\n",
      "('Reading image:', 'datasets/train\\\\cat.10107.jpg')\n",
      "('Reading image:', 'datasets/train\\\\cat.10108.jpg')\n",
      "('Reading image:', 'datasets/train\\\\cat.10109.jpg')\n",
      "('Reading image:', 'datasets/train\\\\cat.1011.jpg')\n",
      "('Reading image:', 'datasets/train\\\\cat.10110.jpg')\n",
      "('Reading image:', 'datasets/train\\\\cat.10111.jpg')\n",
      "('Reading image:', 'datasets/train\\\\cat.10112.jpg')\n",
      "('Reading image:', 'datasets/train\\\\cat.10113.jpg')\n",
      "('Reading image:', 'datasets/train\\\\cat.10114.jpg')\n",
      "('Reading image:', 'datasets/train\\\\cat.10115.jpg')\n",
      "('Reading image:', 'datasets/train\\\\cat.10116.jpg')\n",
      "('Reading image:', 'datasets/train\\\\cat.10117.jpg')\n",
      "('Reading image:', 'datasets/train\\\\cat.10118.jpg')\n",
      "('Reading image:', 'datasets/train\\\\cat.10119.jpg')\n",
      "('Reading image:', 'datasets/train\\\\cat.1012.jpg')\n",
      "('Reading image:', 'datasets/train\\\\cat.10120.jpg')\n",
      "('Reading image:', 'datasets/train\\\\cat.10121.jpg')\n",
      "('Reading image:', 'datasets/train\\\\cat.10122.jpg')\n",
      "('Reading image:', 'datasets/train\\\\cat.10123.jpg')\n",
      "('Reading image:', 'datasets/train\\\\cat.10124.jpg')\n",
      "('Reading image:', 'datasets/train\\\\cat.10125.jpg')\n",
      "('Reading image:', 'datasets/train\\\\cat.10126.jpg')\n",
      "('Reading image:', 'datasets/train\\\\cat.10127.jpg')\n",
      "('Reading image:', 'datasets/train\\\\cat.10128.jpg')"
     ]
    }
   ],
   "source": [
    "all_instance_filenames = []\n",
    "all_instance_targets = []\n",
    "for f in glob.glob('datasets/train/*.jpg'):\n",
    "    target = 1 if 'cat' in f else 0\n",
    "    all_instance_filenames.append(f)\n",
    "    all_instance_targets.append(target)\n",
    "surf_features = []\n",
    "counter = 0\n",
    "for f in all_instance_filenames:\n",
    "    print('Reading image:', f)\n",
    "    image = mh.imread(f, as_grey=True)\n",
    "    surf_features.append(surf.surf(image)[:, 5:])\n",
    "    \n",
    "train_len = int(len(all_instance_filenames) * .60)\n",
    "X_train_surf_features = np.concatenate(surf_features[:train_len])\n",
    "X_test_surf_feautres = np.concatenate(surf_features[train_len:])\n",
    "y_train = all_instance_targets[:train_len]\n",
    "y_test = all_instance_targets[train_len:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grouping the extracted descriptors into 300 clusters\n",
    "We use MiniBatchKMeans, a variation of K-Means that uses a random\n",
    "sample of the instances in each iteration. As it computes the distances to the\n",
    "centroids for only a sample of the instances in each iteration, MiniBatchKMeans\n",
    "converges more quickly but its clusters' distortions may be greater. In practice,\n",
    "the results are similar, and the trade-off is quite acceptable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_clusters = 300\n",
    "print 'Clustering', len(X_train_surf_features), 'features'\n",
    "estimator = MiniBatchKMeans(n_clusters=n_clusters)\n",
    "estimator.fit_transform(X_train_surf_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructing feature vectors for training and testing data\n",
    "We find the\n",
    "cluster associated with each of the extracted SURF descriptors, and count them using\n",
    "NumPy's binCount() function. The following code will produce a 300-dimensional\n",
    "feature vector for each instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = []\n",
    "for instance in surf_features[:train_len]:\n",
    "    clusters = estimator.predict(instance)\n",
    "    features = np.bincount(clusters)\n",
    "    if len(features) < n_clusters:\n",
    "    features = np.append(features, np.zeros((1, n_clusterslen(features))))\n",
    "    X_train.append(features)\n",
    "    \n",
    "X_test = []\n",
    "for instance in surf_features[train_len:]:\n",
    "    clusters = estimator.predict(instance)\n",
    "    features = np.bincount(clusters)\n",
    "    if len(features) < n_clusters:\n",
    "    features = np.append(features, np.zeros((1, n_clusterslen(features))))\n",
    "    X_test.append(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a logistic regression classifier on the feature vectors and targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = LogisticRegression(C=0.001, penalty='l2')\n",
    "clf.fit_transform(X_train, y_train)\n",
    "predictions = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating our model in terms of Precision, Recall and Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_test, predictions))\n",
    "print('Precision: ', precision_score(y_test, predictions))\n",
    "print('Recall: ', recall_score(y_test, predictions))\n",
    "print('Accuracy: ', accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "In this example we combined clustering with classification in a semi-supervised\n",
    "learning problem. We learnt features by clustering unlabeled data and used it to\n",
    "learn features to build a supervised classifier that can classify\n",
    "images of cats and dogs.\n",
    "\n",
    "This semi-supervised system has better precision and recall than a logistic regression\n",
    "classifier that uses only the pixel intensities as features. Moreover, our feature\n",
    "representations have only 300 dimensions; even small 100 x 100 pixel images would\n",
    "have 10,000 dimensions and hence would prove to be computationally very expensive.\n",
    "\n",
    "___"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
